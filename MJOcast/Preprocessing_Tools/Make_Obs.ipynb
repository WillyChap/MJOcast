{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ccd643-7ed2-4d08-919b-54012438fadb",
   "metadata": {},
   "source": [
    "# What is this notebook?\n",
    "\n",
    "This makes the properly formatted observation file... I suggest using this as a template if you would like to create your own observation file \n",
    "\n",
    "# What do you need to run this? \n",
    "\n",
    "# What should I end up with? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd737e69-4ed8-408f-bd85-c7c6df5658ad",
   "metadata": {},
   "source": [
    "## Load in Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca653ef9-c87d-474e-859d-a97d97b4c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import eofs.standard as Eof_st\n",
    "from eofs.multivariate.standard import MultivariateEof\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b9e9a3-2b19-4901-a5e7-0dfbdd52191e",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114333b5-7cbb-4c30-9735-0a77436988de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#where is your obs file? \n",
    "obs_filez = '/glade/scratch/wchapman/ERA5_uvolr/1deg/ERA5_U_V_TTR_1998_2022.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac54614f-8d7e-4942-b67e-70cd12d3a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ano_dcli(var):\n",
    "    '''return [var_ano, var_dcli], Taxis= axis of time'''\n",
    "    var_dcli=var.groupby('time.dayofyear').mean(dim='time')\n",
    "    var_ano= var.groupby('time.dayofyear') - var_dcli    \n",
    "    return var_ano, var_dcli\n",
    "\n",
    "#grab selected level's...\n",
    "DS_MJOera5 = xr.open_dataset(obs_filez) #\n",
    "DS_MJOera5['u200']=DS_MJOera5['U'].sel(level=200)\n",
    "DS_MJOera5['u850']=DS_MJOera5['U'].sel(level=850)\n",
    "DS_MJOera5['v200']=DS_MJOera5['V'].sel(level=200)\n",
    "DS_MJOera5['v850']=DS_MJOera5['V'].sel(level=850)\n",
    "\n",
    "#test for NAN values... adjust variable names: \n",
    "nan_time_slice = DS_MJOera5.u200.where(np.isnan(DS_MJOera5.u200), drop=True)\n",
    "if len(nan_time_slice.time)>0:\n",
    "    nan_time_slice_u200 = DS_MJOera5.u200.where(np.isnan(DS_MJOera5.u200), drop=True)\n",
    "    print('check u200 for nans')\n",
    "    #add your fix for NANs here: \n",
    "    time_indices = np.where(DS_MJOera5['u200'].time == np.datetime64(str(nan_time_slice_u200.time.values[0])))[0]\n",
    "    DS_MJOera5['u200'][time_indices[0],:,:]=DS_MJOera5['u200'][time_indices[0]+1,:,:]\n",
    "nan_time_slice = DS_MJOera5.u850.where(np.isnan(DS_MJOera5.u850), drop=True)\n",
    "if len(nan_time_slice.time)>0:\n",
    "    nan_time_slice_u850 = DS_MJOera5.u850.where(np.isnan(DS_MJOera5.u850), drop=True)\n",
    "    print('check u850 for nans')\n",
    "if len(nan_time_slice.time)>0:\n",
    "    nan_time_slice_ulwrf = DS_MJOera5.ulwrf.where(np.isnan(DS_MJOera5.TTR), drop=True)\n",
    "    print('check ulwrf for nans')\n",
    "\n",
    "\n",
    "## adjust the following if needed... must have variables u,u,ttr\n",
    "# DS_MJOera5 = DS_MJOera5.mean('latitude')\n",
    "u200era20c = DS_MJOera5.u200\n",
    "u200era20c = u200era20c.rename('u')\n",
    "u850era20c = DS_MJOera5.u850\n",
    "u850era20c = u850era20c.rename('u')\n",
    "uOLRera20c = DS_MJOera5.TTR\n",
    "uOLRera20c = uOLRera20c.rename('ttr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df5fc3-2ad5-4d39-960f-56137dbf60e9",
   "metadata": {},
   "source": [
    "## Process Three Variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03960356-d1b2-4d4d-a2b8-9ba24b1e097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "OLR = DS_MJOera5.TTR.to_dataset().rename_vars({'TTR':'olr'}).sel(lat=slice(16,-16))\n",
    "U200 = DS_MJOera5.u200.to_dataset().rename_vars({'u200':'uwnd'}).sel(lat=slice(16,-16))\n",
    "U850 = DS_MJOera5.u850.to_dataset().rename_vars({'u850':'uwnd'}).sel(lat=slice(16,-16))\n",
    "\n",
    "OLR = OLR.mean('lat')\n",
    "U200 = U200.mean('lat')\n",
    "U850 = U850.mean('lat')\n",
    "\n",
    "print(' ----- Computing daily anomalies + climatologies ----- ')\n",
    "OLR_anom,OLR_clim = cal_ano_dcli(OLR)\n",
    "U850_anom,U850_clim = cal_ano_dcli(U850)\n",
    "U200_anom,U200_clim = cal_ano_dcli(U200)\n",
    "\n",
    "print(' ----- Removing interannual variability (120d rolling mean) ----- ')\n",
    "OLR_anom2 = OLR_anom - OLR_anom.rolling(time=120, center=False).mean().dropna('time')\n",
    "print('...1...')\n",
    "U850_anom2 = U850_anom - U850_anom.rolling(time=120, center=False).mean().dropna('time')\n",
    "print('...2...')\n",
    "U200_anom2 = U200_anom - U200_anom.rolling(time=120, center=False).mean().dropna('time')\n",
    "print('...done...')\n",
    "\n",
    "DSanom = xr.merge([U850_anom.rename({'uwnd':'uwnd850'}),U200_anom.rename({'uwnd':'uwnd200'}),OLR_anom]).to_netcdf('./Observations/ERA5_Meridional_Mean_Anomaly.nc')\n",
    "DSanom_filt = xr.merge([U850_anom.rename({'uwnd':'uwnd850'}),U200_anom.rename({'uwnd':'uwnd200'}),OLR_anom]).to_netcdf('./Observations/ERA5_Meridional_Mean_Anomaly_Filtered120.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2023b",
   "language": "python",
   "name": "npl-2023b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
